{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e91d36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from math import sqrt, pi, exp\n",
    "import scipy.linalg\n",
    "import time\n",
    "import matplotlib.pylab as pl\n",
    "from scipy.sparse.linalg import eigs\n",
    "import math\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "from eki_code.grad_inference import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbff29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "alpha = 1.0\n",
    "J = 20  # number of particles \n",
    "N_sim = 20000 # number of iterations\n",
    "d = 2 # dimension\n",
    "tau = 0.01 # step size\n",
    "u0 = np.random.normal(0,1.0,(2,J)) # initial position of the particles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "760fbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case \"banana\"\n",
    "y = 0\n",
    "sigNoise = 0.5\n",
    "sigPrior = 2\n",
    "\n",
    "xmin = -2\n",
    "xmax = 7\n",
    "ymin= -1\n",
    "ymax= 5\n",
    "\n",
    "G = lambda u: ((u[1]-2)**2-(u[0]-3.5) -1)\n",
    "Phi = lambda u: 0.5/(sigNoise**2)*(G(u)-y)**2 #likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "647f0c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Posterior distribution')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# potential function\n",
    "I = lambda u: Phi(u) + 0.5/(sigPrior**2)*np.linalg.norm(u,axis=0)**2\n",
    "\n",
    "\n",
    "# Plot test case\n",
    "u0s = np.linspace(xmin,xmax,150)\n",
    "u1s = np.linspace(ymin,ymax,150)\n",
    "U0, U1 = np.meshgrid(u0s,u1s)\n",
    "U = np.stack((U0,U1))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.contourf(U0, U1, np.exp(-I(U)), 10)\n",
    "plt.title(\"Posterior distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9236f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for computing all gradients at once\n",
    "def compute_gradients(points):\n",
    "    vs = np.zeros_like(points)\n",
    "    d, J = points.shape\n",
    "    H = np.zeros((points.shape[0],points.shape[0],points.shape[1]))\n",
    "    for i in range(J):\n",
    "        return_dict= inferGradientAndHess(points, I(points), hessian = True, ind=i, additionalvariance=0.0)\n",
    "        vs[:,i], H[:,:,i] = return_dict['grad'], return_dict['H']\n",
    "    return vs, H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09c19e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart_time = time.time()\\nus_list_ALDI = np.zeros((d,J,N_sim))\\nus_list_ALDI[:,:,0] = u0\\ntotal_acc = 0\\ntau_ALDI = tau\\n\\n\\ny_algo = np.array([[y]])\\nfor n in range(N_sim-1):   \\n    us = us_list_ALDI[:,:,n]\\n    m_us = np.mean(us, axis=1)[:,np.newaxis]\\n    G_us_unprocessed = G(us)\\n    #if G_us_unprocessed.ndim == 1: # this is just to catch an annoying thing when G has higher dimension\\n    G_us = G_us_unprocessed[np.newaxis,:]\\n    m_G_us = np.mean(G_us, axis=1)[np.newaxis, :]\\n    #else:\\n    #    G_us = G_us_unprocessed.T\\n    #    m_G_us = np.mean(G_us, axis=1)[:,np.newaxis]\\n    #m_G_us =  np.mean(G(us)[np.newaxis,:], axis=1)[np.newaxis, :]\\n    u_c = us-m_us \\n    g_c = G_us- m_G_us\\n    D = 1/J*np.einsum(\\'ij,lj->il\\', u_c, g_c) \\n    C = np.cov(us)*(J-1)/J \\n    E = np.cov(G_us)*(J-1)/J\\n    Csqrt = 1/sqrt(J)*u_c\\n\\n    drift = -1/(sigNoise**2+ tau_ALDI*E)*D@(G_us-y_algo) - 1/sigPrior**2*C@us + (d+1)*1/J*(us-m_us)\\n    noise = np.random.normal(0,1,(J,J))\\n    diff = sqrt(2)*Csqrt@noise\\n\\n    us_list_ALDI[:,:,n+1] = us+tau_ALDI*drift  + sqrt(tau_ALDI)*diff\\n    \\nprint(f\"ALDI without gradient: {time.time()-start_time} seconds\")\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EKS (ALDI)\n",
    "\"\"\"\n",
    "start_time = time.time()\n",
    "us_list_ALDI = np.zeros((d,J,N_sim))\n",
    "us_list_ALDI[:,:,0] = u0\n",
    "total_acc = 0\n",
    "tau_ALDI = tau\n",
    "\n",
    "\n",
    "y_algo = np.array([[y]])\n",
    "for n in range(N_sim-1):   \n",
    "    us = us_list_ALDI[:,:,n]\n",
    "    m_us = np.mean(us, axis=1)[:,np.newaxis]\n",
    "    G_us_unprocessed = G(us)\n",
    "    #if G_us_unprocessed.ndim == 1: # this is just to catch an annoying thing when G has higher dimension\n",
    "    G_us = G_us_unprocessed[np.newaxis,:]\n",
    "    m_G_us = np.mean(G_us, axis=1)[np.newaxis, :]\n",
    "    #else:\n",
    "    #    G_us = G_us_unprocessed.T\n",
    "    #    m_G_us = np.mean(G_us, axis=1)[:,np.newaxis]\n",
    "    #m_G_us =  np.mean(G(us)[np.newaxis,:], axis=1)[np.newaxis, :]\n",
    "    u_c = us-m_us \n",
    "    g_c = G_us- m_G_us\n",
    "    D = 1/J*np.einsum('ij,lj->il', u_c, g_c) \n",
    "    C = np.cov(us)*(J-1)/J \n",
    "    E = np.cov(G_us)*(J-1)/J\n",
    "    Csqrt = 1/sqrt(J)*u_c\n",
    "\n",
    "    drift = -1/(sigNoise**2+ tau_ALDI*E)*D@(G_us-y_algo) - 1/sigPrior**2*C@us + (d+1)*1/J*(us-m_us)\n",
    "    noise = np.random.normal(0,1,(J,J))\n",
    "    diff = sqrt(2)*Csqrt@noise\n",
    "\n",
    "    us_list_ALDI[:,:,n+1] = us+tau_ALDI*drift  + sqrt(tau_ALDI)*diff\n",
    "    \n",
    "print(f\"ALDI without gradient: {time.time()-start_time} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ca50127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart_time = time.time()\\nus_list_ALDI2 = np.zeros((d,J,N_sim))\\nus_list_ALDI2[:,:,0] = u0\\ntotal_acc = 0\\ntau_ALDI2 = tau\\n\\ny_algo = np.array([[y]])\\nfor n in range(N_sim-1):   \\n    us = us_list_ALDI2[:,:,n]\\n    m_us = np.mean(us, axis=1)[:,np.newaxis]\\n    G_us_unprocessed = G(us)\\n    #if G_us_unprocessed.ndim == 1: # this is just to catch an annoying thing when G has higher dimension\\n    G_us = G_us_unprocessed[np.newaxis,:]\\n    m_G_us = np.mean(G_us, axis=1)[np.newaxis, :]\\n    #else:\\n    #    G_us = G_us_unprocessed.T\\n    #    m_G_us = np.mean(G_us, axis=1)[:,np.newaxis]\\n    #m_G_us =  np.mean(G(us)[np.newaxis,:], axis=1)[np.newaxis, :]\\n    u_c = us-m_us \\n    g_c = G_us- m_G_us\\n    D = 1/J*np.einsum(\\'ij,lj->il\\', u_c, g_c) \\n    C = np.cov(us)*(J-1)/J \\n    E = np.cov(G_us)*(J-1)/J\\n    Csqrt = 1/sqrt(J)*u_c\\n    \\n    vs, H = compute_gradients(us_list_ALDI2[:,:,n])\\n    \\n    #drift = -1/(sigNoise**2 + tau_ALDI*E)*D@(G_us-y_algo) - 1/sigPrior**2*C@us + (d+1)*1/J*(us-m_us) # original line\\n    drift = - np.dot(C,vs) + (d+1)*1/J*(us-m_us) \\n    noise = np.random.normal(0,1,(J,J))\\n    diff = sqrt(2)*Csqrt@noise\\n    \\n    #print(Csqrt.shape)\\n    #print(noise.shape)\\n    \\n    us_list_ALDI2[:,:,n+1] = us+tau_ALDI2*drift  + sqrt(tau_ALDI2)*diff\\nprint(f\"ALDI with gradient: {time.time()-start_time} seconds\")\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EKS 2 (ALDI with gradient)\n",
    "\"\"\"\n",
    "start_time = time.time()\n",
    "us_list_ALDI2 = np.zeros((d,J,N_sim))\n",
    "us_list_ALDI2[:,:,0] = u0\n",
    "total_acc = 0\n",
    "tau_ALDI2 = tau\n",
    "\n",
    "y_algo = np.array([[y]])\n",
    "for n in range(N_sim-1):   \n",
    "    us = us_list_ALDI2[:,:,n]\n",
    "    m_us = np.mean(us, axis=1)[:,np.newaxis]\n",
    "    G_us_unprocessed = G(us)\n",
    "    #if G_us_unprocessed.ndim == 1: # this is just to catch an annoying thing when G has higher dimension\n",
    "    G_us = G_us_unprocessed[np.newaxis,:]\n",
    "    m_G_us = np.mean(G_us, axis=1)[np.newaxis, :]\n",
    "    #else:\n",
    "    #    G_us = G_us_unprocessed.T\n",
    "    #    m_G_us = np.mean(G_us, axis=1)[:,np.newaxis]\n",
    "    #m_G_us =  np.mean(G(us)[np.newaxis,:], axis=1)[np.newaxis, :]\n",
    "    u_c = us-m_us \n",
    "    g_c = G_us- m_G_us\n",
    "    D = 1/J*np.einsum('ij,lj->il', u_c, g_c) \n",
    "    C = np.cov(us)*(J-1)/J \n",
    "    E = np.cov(G_us)*(J-1)/J\n",
    "    Csqrt = 1/sqrt(J)*u_c\n",
    "    \n",
    "    vs, H = compute_gradients(us_list_ALDI2[:,:,n])\n",
    "    \n",
    "    #drift = -1/(sigNoise**2 + tau_ALDI*E)*D@(G_us-y_algo) - 1/sigPrior**2*C@us + (d+1)*1/J*(us-m_us) # original line\n",
    "    drift = - np.dot(C,vs) + (d+1)*1/J*(us-m_us) \n",
    "    noise = np.random.normal(0,1,(J,J))\n",
    "    diff = sqrt(2)*Csqrt@noise\n",
    "    \n",
    "    #print(Csqrt.shape)\n",
    "    #print(noise.shape)\n",
    "    \n",
    "    us_list_ALDI2[:,:,n+1] = us+tau_ALDI2*drift  + sqrt(tau_ALDI2)*diff\n",
    "print(f\"ALDI with gradient: {time.time()-start_time} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf8b7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: covariance matrix C, dimension d, prefactor c\n",
    "\n",
    "def construct_D_opt_tilde(C,d):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "    index_min = np.argmin(eigenvalues)\n",
    "    lambda_min = eigenvalues[index_min]\n",
    "    v = eigenvectors[:,index_min]\n",
    "    D_opt_tilde = (d/lambda_min)*np.tensordot(v,v,axes = 0) # D is symmetric \n",
    "    return D_opt_tilde, v, lambda_min\n",
    "\n",
    "\n",
    "def construct_onb(d,v):\n",
    "    e_1, e_2 = np.eye(d)[:,0], np.eye(d)[:,1]\n",
    "    xi = (1/np.sqrt(d))*(e_1+e_2)\n",
    "    dot_product =  np.dot(xi,v) \n",
    "    theta =  math.acos(dot_product) # removed minus sign\n",
    "    difference = xi - dot_product*v \n",
    "    v_prime = difference/np.linalg.norm(difference)\n",
    "    v_processed = v[np.newaxis,:].T\n",
    "    v_prime_processed = v_prime[np.newaxis,:].T\n",
    "    V = np.concatenate((v_processed,v_prime_processed), axis = 1) # I obtain a symmetric matrix\n",
    "\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "\n",
    "    A_theta1 = np.array(((c, -s), (s, c))) \n",
    "    A_theta2 = np.array(((c, s), (-s, c)))\n",
    "\n",
    "    if np.linalg.norm(np.dot(A_theta1,xi)-v)< 1e-8:\n",
    "       A_theta = A_theta1\n",
    "    elif np.linalg.norm(np.dot(A_theta2,xi)-v)< 1e-8:\n",
    "       A_theta = A_theta2 \n",
    "    else:\n",
    "        print(\"error\")\n",
    "    \n",
    "    T = V.dot(A_theta).dot(V.T)\n",
    "\n",
    "    psis = np.zeros((d,d))\n",
    "    #e_1_parallel = ((np.dot(e_1,xi) - dot_product*np.dot(e_1,v))/(1-dot_product**2))*xi + \\\n",
    "    #                ((np.dot(e_1,v) - dot_product*np.dot(e_1,xi))/(1-dot_product**2))*v \n",
    "    e_1_parallel = np.dot(e_1,xi)*xi +np.dot(e_1,v)*v\n",
    "    e_1_orthogonal = e_1 - e_1_parallel\n",
    "    psi_1 = np.dot(T,e_1_parallel) + e_1_orthogonal\n",
    "    psis[:,0]= psi_1\n",
    "\n",
    "    #e_2_parallel = ((np.dot(e_2,xi) - dot_product*np.dot(e_2,v))/(1-dot_product**2))*xi + \\\n",
    "    #                ((np.dot(e_2,v) - dot_product*np.dot(e_2,xi))/(1-dot_product**2))*v \n",
    "    e_2_parallel = np.dot(e_2,xi)*xi +np.dot(e_2,v)*v\n",
    "    e_2_orthogonal = e_2 - e_2_parallel\n",
    "    psi_2 = np.dot(T,e_2_parallel) + e_2_orthogonal\n",
    "    psis[:,1]= psi_2\n",
    "\n",
    "    return psis\n",
    "\n",
    "#def construct_J_opt(psis, v, c, sqrtC, d, lambd):\n",
    "#    lambda_min = lambd\n",
    "#    J_hat = np.zeros((d,d))\n",
    "\n",
    "#    lambda_1 = 1\n",
    "#    lambda_2 = c**2\n",
    "#    lambdas = [lambda_1, lambda_2]\n",
    "\n",
    "#    for j in range(2):\n",
    "#        for k in range(j+1,2):       \n",
    "#            J_hat[j,k] = ((lambdas[j]+lambdas[k])/(lambdas[j]-lambdas[k]))*np.dot(v,psis[j])*np.dot(v,psis[k])\n",
    "#            J_hat[k,j] = - J_hat[j,k]\n",
    "\n",
    "#    J_opt = functools.reduce(np.dot, [sqrtC, psis, J_hat, psis.T, sqrtC])\n",
    "#    return J_opt\n",
    "\n",
    "\n",
    "def construct_J_opt_tilde(psis, v, c, d, lambd):\n",
    "    lambda_min = lambd\n",
    "    J_hat = np.zeros((d,d))\n",
    "\n",
    "    lambda_1 = 1\n",
    "    lambda_2 = c**2\n",
    "    lambdas = [lambda_1, lambda_2]\n",
    "\n",
    "    for j in range(2):\n",
    "        for k in range(j+1,2):       \n",
    "            J_hat[j,k] = ((lambdas[j]+lambdas[k])/(lambdas[j]-lambdas[k]))*np.dot(v,psis[j])*np.dot(v,psis[k])\n",
    "            J_hat[k,j] = - J_hat[j,k]\n",
    "\n",
    "    J_opt = functools.reduce(np.dot, [ psis, J_hat, psis.T])\n",
    "    return J_opt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f589392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: \n",
      "[[ 1.20957205 -0.04488609]\n",
      " [-0.04488609  0.64749842]]\n",
      "\n",
      "eigenvalues of C :\n",
      "[1.21313399 0.64393647]\n",
      "\n",
      "d opt\n",
      "[[0.01251566 0.15771708]\n",
      " [0.15771708 1.98748434]]\n",
      "evalues of dopt\n",
      "[-0.  2.]\n",
      "sqrt d\n",
      "[[0.00884991 0.11152282]\n",
      " [0.11152282 1.40536365]]\n",
      "T\n",
      "[[ 0.01251566 -0.09959277]\n",
      " [ 0.41502694  1.98748434]]\n",
      "evalues of topt\n",
      "[0.0337 1.9663]\n",
      "0\n",
      "C: \n",
      "[[ 1.24776762 -0.43651312]\n",
      " [-0.43651312  1.36990936]]\n",
      "\n",
      "eigenvalues of C :\n",
      "[0.86807398 1.749603  ]\n",
      "\n",
      "d opt\n",
      "[[1.13855668 0.99035451]\n",
      " [0.99035451 0.86144332]]\n",
      "evalues of dopt\n",
      "[ 2. -0.]\n",
      "sqrt d\n",
      "[[0.80508115 0.70028639]\n",
      " [0.70028639 0.60913241]]\n",
      "T\n",
      "[[  1.13855668  32.06217542]\n",
      " [-30.08146641   0.86144332]]\n",
      "evalues of topt\n",
      "[1.+31.0557j 1.-31.0557j]\n",
      "C: \n",
      "[[746.96337895  82.07939541]\n",
      " [ 82.07939541  11.67996209]]\n",
      "\n",
      "eigenvalues of C :\n",
      "[756.01445373   2.6288873 ]\n",
      "\n",
      "d opt\n",
      "[[ 0.02402774 -0.21789479]\n",
      " [-0.21789479  1.97597226]]\n",
      "evalues of dopt\n",
      "[0. 2.]\n",
      "sqrt d\n",
      "[[ 0.01699018 -0.15407488]\n",
      " [-0.15407488  1.39722339]]\n",
      "T\n",
      "[[  0.02402774 -10.60396974]\n",
      " [ 10.16818016   1.97597226]]\n",
      "evalues of topt\n",
      "[1.+10.3378j 1.-10.3378j]\n",
      "C: \n",
      "[[ 562025.76386665 -116896.76515393]\n",
      " [-116896.76515393   25405.48083431]]\n",
      "\n",
      "eigenvalues of C :\n",
      "[586384.69441632   1046.55028464]\n",
      "\n",
      "d opt\n",
      "[[0.08323029 0.39941619]\n",
      " [0.39941619 1.91676971]]\n",
      "evalues of dopt\n",
      "[0. 2.]\n",
      "sqrt d\n",
      "[[0.0588527  0.2824299 ]\n",
      " [0.2824299  1.35536086]]\n",
      "T\n",
      "[[ 8.32302860e-02 -9.67336860e+03]\n",
      " [ 9.67416743e+03  1.91676971e+00]]\n",
      "evalues of topt\n",
      "[1.+9673.768j 1.-9673.768j]\n",
      "C: \n",
      "[[7.05927387e+13 3.37164996e+14]\n",
      " [3.37164996e+14 1.61068866e+15]]\n",
      "\n",
      "eigenvalues of C :\n",
      "[1.34951566e+10 1.68126790e+15]\n",
      "\n",
      "d opt\n",
      "[[ 1.91603978 -0.40108742]\n",
      " [-0.40108742  0.08396022]]\n",
      "evalues of dopt\n",
      "[2. 0.]\n",
      "sqrt d\n",
      "[[ 1.35484472 -0.28361163]\n",
      " [-0.28361163  0.05936884]]\n",
      "T\n",
      "[[ 1.91681776e+00 -1.05825040e+12]\n",
      " [ 1.05825040e+12  9.71309687e-02]]\n",
      "evalues of topt\n",
      "[1.007+1.0582504e+12j 1.007-1.0582504e+12j]\n",
      "C: \n",
      "[[ 2.37668510e+25 -4.97842578e+24]\n",
      " [-4.97842578e+24  1.04282812e+24]]\n",
      "\n",
      "eigenvalues of C :\n",
      "[2.48096785e+25 6.94940113e+17]\n",
      "\n",
      "d opt\n",
      "[[0.08406618 0.40132934]\n",
      " [0.40132934 1.91593382]]\n",
      "evalues of dopt\n",
      "[0. 2.]\n",
      "sqrt d\n",
      "[[0.05944377 0.2837827 ]\n",
      " [0.2837827  1.3547698 ]]\n",
      "T\n",
      "[[ 2.46091266e+08 -1.62567250e+21]\n",
      " [ 1.62567250e+21 -6.20999626e+06]]\n",
      "evalues of topt\n",
      "[1.1991908e+08+1.6256725e+21j 1.1991908e+08-1.6256725e+21j]\n",
      "C: \n",
      "[[1.68127233e+32 8.02593853e+32]\n",
      " [8.02593853e+32 3.83136616e+33]]\n",
      "\n",
      "eigenvalues of C :\n",
      "[2.44088401e+25 3.99949337e+33]\n",
      "\n",
      "d opt\n",
      "[[ 1.91592575 -0.40134776]\n",
      " [-0.40134776  0.08407425]]\n",
      "evalues of dopt\n",
      "[ 2. -0.]\n",
      "sqrt d\n",
      "[[ 1.35476409 -0.28379572]\n",
      " [-0.28379572  0.05944947]]\n",
      "T\n",
      "[[-9.95912611e+15 -6.98452684e+28]\n",
      " [ 6.98452684e+28 -2.01941309e+17]]\n",
      "evalues of topt\n",
      "[-1.05952358e+17+6.98452684e+28j -1.05952358e+17-6.98452684e+28j]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_t/h78tns5s2990dvmw2d6kzfyw0000gn/T/ipykernel_919/263603882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluesT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Ensuring square root matrix exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevaluesT\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Non reversible EKS (our algorithm) v2\n",
    "\n",
    "start_time = time.time()\n",
    "us_list_ALDINR = np.zeros((d,J,N_sim))\n",
    "us_list_ALDINR[:,:,0] = u0\n",
    "total_acc = 0\n",
    "tau_ALDINR = tau\n",
    "tol = 1e-3\n",
    "\n",
    "#N_max= 90\n",
    "\n",
    "y_algo = np.array([[y]])\n",
    "for n in range(N_sim-1):   \n",
    "    us = us_list_ALDINR[:,:,n] # shape (d, J)\n",
    "    m_us = np.mean(us, axis=1)[:,np.newaxis] # shape (2, 1)\n",
    "    G_us_unprocessed = G(us)   \n",
    "    G_us = G_us_unprocessed[np.newaxis,:] # shape (dim_G, 20)\n",
    "    m_G_us = np.mean(G_us, axis=1)[np.newaxis, :] # shape (dim_G, dim_G)\n",
    "    u_c = us - m_us # shape (2, 20) \n",
    "    g_c = G_us- m_G_us # shape (dim_G, 20)\n",
    "    D = 1/J*np.einsum('ij,lj->il', u_c, g_c) # shape (2, 1) = (d, dim_G)\n",
    "    C = np.cov(us)*(J-1)/J # shape (2,2)\n",
    "    Csqrt = 1/sqrt(J)*u_c # shape (2, 20)\n",
    "    \n",
    "    # compute sqrt C\n",
    "    print(\"C: \")\n",
    "    print(C)\n",
    "    print()\n",
    "    evaluesC, evectorsC = np.linalg.eig(C)\n",
    "    # Ensuring square root matrix exists\n",
    "    print(\"eigenvalues of C :\")\n",
    "    print(evaluesC)\n",
    "    print()\n",
    "    assert (evaluesC >= 0).all()\n",
    "    sqrtC = evectorsC * np.sqrt(evaluesC) @ evectorsC.T \n",
    "    \n",
    "    D_opt_tilde, test_v, lambda_min = construct_D_opt_tilde(C,2)\n",
    "    D_opt = lambda_min *D_opt_tilde\n",
    "    print('d opt')\n",
    "    print(D_opt)\n",
    "    \n",
    "    # compute sqrt D\n",
    "    evaluesD, evectorsD = np.linalg.eig(D_opt)\n",
    "    evaluesD = evaluesD.round(decimals = 4, out = None)\n",
    "    print('evalues of dopt')\n",
    "    print(evaluesD)\n",
    "    # Ensuring square root matrix exists\n",
    "    assert (evaluesD >= -tol).all()\n",
    "    sqrtD = evectorsD * np.sqrt(evaluesD) @ evectorsD.T \n",
    "    print('sqrt d')\n",
    "    print(sqrtD)\n",
    "       \n",
    "    psis = construct_onb(d,test_v)\n",
    "    \n",
    "    \n",
    "    #test jopt bis\n",
    "    J_opt_tilde = construct_J_opt_tilde(psis, test_v, 1.8, 2, lambda_min) # shape (2, 2)\n",
    "    J_opt = functools.reduce(np.dot, [sqrtC, J_opt_tilde, sqrtC])\n",
    "    \n",
    "    T = D_opt + J_opt\n",
    "    print(\"T\")\n",
    "    print(T)\n",
    "    evaluesT, evectorsT = np.linalg.eig(T)\n",
    "    evaluesT = evaluesT.round(decimals = 4, out = None)\n",
    "    print('evalues of topt')\n",
    "    print(evaluesT)\n",
    "    # Ensuring square root matrix exists\n",
    "    assert (evaluesT >= -tol).all()\n",
    "    \n",
    "    vs, H = compute_gradients(us)\n",
    "    \n",
    "    #drift = - np.dot(D_opt,vs) - Csqrt.T@J_optbis@Csqrt + (d+1)*1/J*(us-m_us) # shape (2,20)\n",
    "    drift = - np.dot(T,vs) + (d+1)*1/J*(us-m_us)\n",
    "    #noise = np.random.normal(0,1,(2,J))\n",
    "    #print(noise.shape)\n",
    "    #diff = sqrt(2)*np.dot(sqrtD,noise) # CHANGE TO SQRT D\n",
    "    #print(str('diff'))\n",
    "    #print(diff)\n",
    "    \n",
    "    us_list_ALDINR[:,:,n+1] = us+tau_ALDINR*drift  #+ sqrt(tau_ALDINR)*diff\n",
    "    #print(us_list_ALDINR[:,:,n+1])\n",
    "    if np.mod(n,500)==0:\n",
    "        print(n)\n",
    "    #print(C)\n",
    "    \n",
    "print(f\"ALDI: {time.time()-start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "C\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "index_min = np.argmin(eigenvalues)\n",
    "lambda_min = eigenvalues[index_min]\n",
    "v = eigenvectors[:,index_min]\n",
    "D_opt = (d/lambda_min)*np.tensordot(v,v,axes = 0) # D is symmetric \n",
    "D_optbis = (d/lambda_min)*np.tensordot(v.T,v.T,axes = 0)\n",
    "\n",
    "\n",
    "e_1, e_2 = np.eye(d)[:,0], np.eye(d)[:,1]\n",
    "xi = (1/np.sqrt(d))*(e_1+e_2)\n",
    "dot_product =  np.dot(xi,v) \n",
    "theta =  math.acos(dot_product) # check with minus sign\n",
    "difference = xi - dot_product*v \n",
    "v_prime = difference/np.linalg.norm(difference)\n",
    "v_processed = v[np.newaxis,:].T\n",
    "v_prime_processed = v_prime[np.newaxis,:].T\n",
    "V = np.concatenate((v_processed,v_prime_processed), axis = 1) # I obtain a symmetric matrix such that V.T*V = Id\n",
    "\n",
    "c, s = np.cos(theta), np.sin(theta)\n",
    "A_theta = np.array(((c, -s), s, c))\n",
    "T = V.dot(A_theta).dot(V.T)\n",
    "\n",
    "psis = np.zeros((d,d))\n",
    "e_1_parallel = ((np.dot(e_1,xi) - dot_product*np.dot(e_1,v))/(1-dot_product**2))*xi + \\\n",
    "                ((np.dot(e_1,v) - dot_product*np.dot(e_1,xi))/(1-dot_product**2))*v \n",
    "e_1_orthogonal = e_1 - e_1_parallel\n",
    "psi_1 = np.dot(T,e_1_parallel) + e_1_orthogonal\n",
    "psis[:,0]= psi_1\n",
    "\n",
    "e_2_parallel = ((np.dot(e_2,xi) - dot_product*np.dot(e_2,v))/(1-dot_product**2))*xi + \\\n",
    "                ((np.dot(e_2,v) - dot_product*np.dot(e_2,xi))/(1-dot_product**2))*v \n",
    "e_2_orthogonal = e_2 - e_2_parallel\n",
    "psi_2 = np.dot(T,e_2_parallel) + e_2_orthogonal\n",
    "psis[:,1]= psi_2\n",
    "\n",
    "print(psis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.dot(T,xi))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02aee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non reversible EKS (our algorithm) old version\n",
    "\"\"\"\n",
    "start_time = time.time()\n",
    "us_list_ALDINR = np.zeros((d,J,N_sim))\n",
    "us_list_ALDINR[:,:,0] = u0\n",
    "total_acc = 0\n",
    "tau_ALDINR = tau\n",
    "\n",
    "\n",
    "y_algo = np.array([[y]])\n",
    "for n in range(N_sim-1):   \n",
    "    us = us_list_ALDINR[:,:,n]\n",
    "    m_us = np.mean(us, axis=1)[:,np.newaxis]\n",
    "    G_us_unprocessed = G(us)\n",
    "    #if G_us_unprocessed.ndim == 1: # this is just to catch an annoying thing when G has higher dimension\n",
    "    G_us = G_us_unprocessed[np.newaxis,:]\n",
    "    m_G_us = np.mean(G_us, axis=1)[np.newaxis, :]\n",
    "    #else:\n",
    "    #    G_us = G_us_unprocessed.T\n",
    "    #    m_G_us = np.mean(G_us, axis=1)[:,np.newaxis]\n",
    "    #m_G_us =  np.mean(G(us)[np.newaxis,:], axis=1)[np.newaxis, :]\n",
    "    u_c = us-m_us \n",
    "    g_c = G_us- m_G_us\n",
    "    D = 1/J*np.einsum('ij,lj->il', u_c, g_c) \n",
    "    C = np.cov(us)*(J-1)/J \n",
    "    E = np.cov(G_us)*(J-1)/J\n",
    "    Csqrt = 1/sqrt(J)*u_c\n",
    "    \n",
    "    # compute sqrt C\n",
    "    evalues, evectors = np.linalg.eig(C)\n",
    "    # Ensuring square root matrix exists\n",
    "    assert (evalues >= 0).all()\n",
    "    sqrtC = evectors * np.sqrt(evalues) @ evectors.T \n",
    "    \n",
    "    D_opt, test_v, lambda_min = construct_D_opt(C,2)\n",
    "    psis = construct_onb(d,test_v)\n",
    "    J_opt = construct_J_opt(psis, test_v, 0.8, sqrtC, 2, lambda_min)\n",
    "    T = D_opt+J_opt\n",
    "    \n",
    "    vs, H = compute_gradients(us_list_ALDINR[:,:,n])\n",
    "    \n",
    "    drift = - np.dot(T,vs) + (d+1)*1/J*(us-m_us)\n",
    "    noise = np.random.normal(0,1,(J,J))\n",
    "    diff = sqrt(2)*Csqrt@noise\n",
    "    \n",
    "    us_list_ALDINR[:,:,n+1] = us+tau_ALDINR*drift  + sqrt(tau_ALDINR)*diff\n",
    "    if np.mod(n,100)==0:\n",
    "        print(n)\n",
    "print(f\"ALDI: {time.time()-start_time} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5401550",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_list_ALDINR[0,:,0:N_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed0b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "\n",
    "N_burnin = 0#1000#int(N_sim/2)\n",
    "\n",
    "\n",
    "binsx = np.linspace(xmin,xmax,31)\n",
    "binsy = np.linspace(ymin,ymax,31)\n",
    "#H1, yedges1, xedges1 = np.histogram2d(us_list_ULA[0,:,N_burnin:].flatten(),us_list_ULA[1,:,N_burnin:].flatten(), bins=[binsx,binsy])\n",
    "H2, yedges2, xedges2 = np.histogram2d(us_list_ALDI[0,:,N_burnin:].flatten(),us_list_ALDI[1,:,N_burnin:].flatten(), bins=[binsx,binsy])\n",
    "H3, yedges3, xedges3 = np.histogram2d(us_list_ALDI2[0,:,N_burnin:].flatten(),us_list_ALDI2[1,:,N_burnin:].flatten(), bins=[binsx,binsy])\n",
    "H4, yedges4, xedges4 = np.histogram2d(us_list_ALDINR[0,:,0:N_max].flatten(),us_list_ALDINR[0,:,0:N_max].flatten(), bins=[binsx,binsy])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "plt.figure()\n",
    "plt.pcolormesh(yedges1, xedges1, H1.T, cmap=pl.cm.viridis_r); \n",
    "plt.xlim((xmin,xmax))\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.contour(U0, U1, np.exp(-I(U)), 5, alpha=0.4, colors=\"black\")\n",
    "plt.title(\"Ensemble Langevin Sampler, J = \"+str(J)+\", N = \"+str(N_sim))\n",
    "\"\"\"\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(yedges2, xedges2, H2.T, cmap=pl.cm.viridis_r); \n",
    "plt.xlim((xmin,xmax))\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.contour(U0, U1, np.exp(-I(U)), 5, alpha=0.4, colors=\"black\")\n",
    "plt.title(\"Ensemble Kalman Sampler without gradient, J = \"+str(J)+\", N = \"+str(N_sim))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(yedges3, xedges3, H3.T, cmap=pl.cm.viridis_r); \n",
    "plt.xlim((xmin,xmax))\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.contour(U0, U1, np.exp(-I(U)), 5, alpha=0.4, colors=\"black\")\n",
    "plt.title(\"Ensemble Kalman Sampler with gradient, J = \"+str(J)+\", N = \"+str(N_sim))\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(yedges4, xedges4, H4.T, cmap=pl.cm.viridis_r); \n",
    "plt.xlim((xmin,xmax))\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.contour(U0, U1, np.exp(-I(U)), 5, alpha=0.4, colors=\"black\")\n",
    "plt.title(\"Non Reversible Ensemble Kalman Sampler with gradient, J = \"+str(J)+\", N = \"+str(N_sim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_list_ALDI2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32438904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932570b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a0338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4ca55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81781ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ed24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a781d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666609ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# draft D opt \n",
    "# input: covariance matrix C, dimension d, prefactor c\n",
    "\n",
    "C0= C\n",
    "#c = 0.8 \n",
    "print(C)\n",
    "\n",
    "# construct Dop\n",
    "eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "print(eigenvalues)\n",
    "print()\n",
    "\n",
    "# v_1, v_2 = eigenvectors[:,0], eigenvectors[:,1]\n",
    "print(eigenvectors)\n",
    "print()\n",
    "\n",
    "\n",
    "index_min = np.argmin(eigenvalues)\n",
    "lambda_min = eigenvalues[index_min]\n",
    "v = eigenvectors[:,index_min]\n",
    "print(v)\n",
    "D_opt = (d/lambda_opt)*np.tensordot(v,v,axes = 0) # D is symmetric \n",
    "print(D_opt)\n",
    "\n",
    "# draft Jopt\n",
    "# find orthonormal basis psi_1,...,psi_d\n",
    "\n",
    "#input dimension ùëë; ùë£ ‚àà Rùëë in the construction of Dopt\n",
    "\n",
    "e_1, e_2 = A = np.eye(d)[:,0], np.eye(d)[:,1]\n",
    "print(e_1)\n",
    "print(e_2)\n",
    "#e_1, e_2 = eigenvectors[:,0], eigenvectors[:,1]\n",
    "xi = (1/np.sqrt(d))*(e_1+e_2)\n",
    "print(xi)\n",
    "print()\n",
    "\n",
    "print(\"construct V\")\n",
    "dot_product =  np.dot(xi,v) \n",
    "theta =    - math.acos(dot_product)\n",
    "difference = xi - dot_product*v \n",
    "v_prime = difference/np.linalg.norm(difference)\n",
    "v_processed = v[np.newaxis,:].T\n",
    "v_prime_processed = v_prime[np.newaxis,:].T\n",
    "#print(\"v processed\")\n",
    "#print(v_processed)\n",
    "#print(v_prime_processed)\n",
    "V = np.concatenate((v_processed,v_prime_processed), axis = 1) # I obtain a symmetric matrix\n",
    "print(\"matrix V\")\n",
    "print(V) \n",
    "print()\n",
    "\n",
    "c, s = np.cos(theta), np.sin(theta)\n",
    "A_theta = np.array(((c, -s), (s, c)))\n",
    "print(str(\"A_theta :\")+str(A_theta))\n",
    "print()\n",
    "\n",
    "T = V.dot(A_theta).dot(V.T)\n",
    "print(str(\"T :\")+str(T))\n",
    "print()\n",
    "\n",
    "# sanity check\n",
    "print(\"sanity check\") # i do not satisfy the sanity check\n",
    "B = np.dot(T,xi)\n",
    "print(B)\n",
    "print(B.shape)\n",
    "print(v)\n",
    "print()\n",
    "\n",
    "psis = np.zeros((d,d))\n",
    "\n",
    "e_1_parallel = ((np.dot(e_1,xi) - dot_product*np.dot(e_1,v))/(1-dot_product**2))*xi + \\\n",
    "                ((np.dot(e_1,v) - dot_product*np.dot(e_1,xi))/(1-dot_product**2))*v \n",
    "e_1_orthogonal = e_1 - e_1_parallel\n",
    "psi_1 = np.dot(T,e_1_parallel) + e_1_orthogonal\n",
    "psis[:,0]= psi_1\n",
    "print(\"psi\")\n",
    "print(psi_1)\n",
    "print()\n",
    "\n",
    "e_2_parallel = ((np.dot(e_2,xi) - dot_product*np.dot(e_2,v))/(1-dot_product**2))*xi + \\\n",
    "                ((np.dot(e_2,v) - dot_product*np.dot(e_2,xi))/(1-dot_product**2))*v \n",
    "e_2_orthogonal = e_2 - e_2_parallel\n",
    "psi_2 = np.dot(T,e_2_parallel) + e_2_orthogonal\n",
    "psis[:,1]= psi_2\n",
    "\n",
    "print(psi_2)\n",
    "print()\n",
    "print(psis)\n",
    "\n",
    "# construct J\n",
    "J_hat = np.zeros((d,d))\n",
    "\n",
    "lambda_1 = 1\n",
    "lambda_2 = c**2\n",
    "lambdas = [lambda_1, lambda_2]\n",
    "\n",
    "for j in range(2):\n",
    "    for k in range(j+1,2):       \n",
    "        J_hat[j,k] = - ((lambdas[j]+lambdas[k])/(lambdas[j]-lambdas[k]))*lambda_opt*np.dot(v,psis[j])*np.dot(v,psis[k])\n",
    "        J_hat[k,j] = - J_hat[j,k]\n",
    "print(J_hat)\n",
    "print(psis.T)\n",
    "\n",
    "J_opt = functools.reduce(np.dot, [C, psis, J_hat, psis.T, C])\n",
    "\n",
    "\n",
    "# test \n",
    "\n",
    "#test_D, test_v, _ = construct_D_opt(C,2)\n",
    "#print(construct_D_opt(C,2))\n",
    "\n",
    "test_psis = construct_onb(d,test_v)\n",
    "print(test_psis)\n",
    "test_J_opt = construct_J_opt(test_psis,test_v, 0.8, C, 2, 1)\n",
    "print(test_J_opt)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
